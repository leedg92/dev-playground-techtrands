from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable

from datetime import datetime, timedelta

# from transformers import pipeline

import requests
import json
import concurrent.futures
import html
import re
import time
import os

# DB ì—°ê²°
from psycopg2 import connect
from psycopg2.extras import execute_values
from psycopg2.extensions import adapt
from psycopg2.extensions import register_adapter


# ìµœì‹  í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
def update_latest_keywords():
    # íŒŒì´í”„ë¼ì¸ ìƒì„±
    # classifier = pipeline(
    #         "zero-shot-classification",
    #         model="facebook/bart-large-mnli"
    # )
    # ë¼ë²¨ ì •ì˜
    # labels = set_labels()
    # tech_labels = set_tech_labels()

    headers = set_headers()
    today = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    # today = '2023-01-01'
    print(f"ðŸ” ìµœì‹  í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ ì‹œìž‘: {today}")

    try:
        
        conn = set_conn()
        print("âœ… DB ì—°ê²° ì„±ê³µ!")
        
        cur = conn.cursor()
        print("ðŸ“ ì»¤ì„œ ìƒì„± ì™„ë£Œ")

        success_list = []
        saved_count = 0

        # DBì—ì„œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹(zero-shot ë¶„ë¥˜ê¸° ë©”ëª¨ë¦¬ ì´ìŠˆ í•´ê²°(ì„œë²„ìš© pcì— íƒ‘ìž¬)ë˜ë©´ ì´ê±¸ë¡œ ì „í™˜)
        # all_tech_keywords = get_tech_keywords_from_db(cur)

        # í•˜ë“œì½”ë”© ë°©ì‹(ì´ê²Œ ë” ë‚«ë‚˜..)
        all_tech_keywords = get_tech_keywords_from_predefined()
        
        for idx, keyword in enumerate(all_tech_keywords):
            # DBì—ì„œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹
            # topic_keyword = keyword[0].lower()

            # í•˜ë“œì½”ë”© ë°©ì‹(ì´ê²Œ ë” ë‚«ë‚˜..)
            topic_keyword = keyword.lower()

            # URL ë¡œê·¸ - í•­ìƒ ì¶œë ¥
            api_url = f'https://api.github.com/search/repositories?q={topic_keyword if topic_keyword == "" else "topic:"+topic_keyword}+stars:>10000+pushed:>{today}'
            print(f"[{idx+1}/{len(all_tech_keywords)}] ðŸŒ API í˜¸ì¶œ: {api_url}")
            
            try:
                topic_keyword_response = requests.get(api_url, headers=headers)
                topic_keyword_data = topic_keyword_response.json()
                
                # API ì‘ë‹µ ìƒíƒœ ë¡œê·¸
                print(f"[{idx+1}/{len(all_tech_keywords)}] ðŸ“¡ API ì‘ë‹µ ìƒíƒœ: {topic_keyword_response.status_code}")
                
                # ì‘ë‹µ ë°ì´í„° ìš”ì•½ ë¡œê·¸
                if 'total_count' in topic_keyword_data:
                    total_count = topic_keyword_data['total_count']
                    print(f"[{idx+1}/{len(all_tech_keywords)}] ðŸ“Š {topic_keyword} ê²€ìƒ‰ ê²°ê³¼: {total_count}ê°œ")
                    
                    if total_count > 0:
                        print(f"[{idx+1}/{len(all_tech_keywords)}] ðŸ’¾ {topic_keyword} ê´€ë ¨ í† í”½ ì €ìž¥ ì‹œìž‘")
                        
                        topic_keyword_list = []
                        for repo in topic_keyword_data['items']:
                            if repo['name']:
                                repo_name = repo['name'].lower()
                                # í•˜ì´í”ˆì´ í¬í•¨ëœ í‚¤ì›Œë“œëŠ” ì œì™¸(ì˜ˆ: python-sdk)
                                if '-' in repo_name:
                                    continue
                                # ai í‚¤ì›Œë“œ ì œì™¸...ë„ˆë¬´ ë§Žì´ ë‚˜ì˜¨ë‹¤..
                                if 'ai' == repo_name:
                                    continue

                                topic_keyword_list.append(repo_name)
                        
                        # DB ì €ìž¥
                        saved_count = 0
                        for new_keyword in topic_keyword_list:
                            cur = save_tech_keywords(cur, new_keyword)
                            
                            if cur.rowcount > 0:  # ì‹¤ì œë¡œ ì‚½ìž…ëœ ê²½ìš°
                                saved_count += 1
                        
                        print(f"[{idx+1}/{len(all_tech_keywords)}] ðŸ’¾ {topic_keyword} ì™„ë£Œ: {saved_count}ê°œ ìƒˆë¡œ ì €ìž¥")
                        success_list.extend(topic_keyword_list)
                    else:
                        print(f"[{idx+1}/{len(all_tech_keywords)}] âš ï¸ {topic_keyword} ê´€ë ¨ í† í”½ ì—†ìŒ")
                else:
                    # API ì—ëŸ¬ ì‘ë‹µ
                    print(f"[{idx+1}/{len(all_tech_keywords)}] âŒ API ì—ëŸ¬ ì‘ë‹µ: {topic_keyword_data}")
                    
            except Exception as api_error:
                print(f"[{idx+1}/{len(all_tech_keywords)}] âŒ API í˜¸ì¶œ ì—ëŸ¬ ({topic_keyword}): {str(api_error)}")
            
            # Rate limit ì¤€ìˆ˜
            print(f"[{idx+1}/{len(all_tech_keywords)}] â³ 2ì´ˆ ëŒ€ê¸°...")

            # ì»¤ë°‹
            conn.commit()
            print("âœ… íŠ¸ëžœìž­ì…˜ ì»¤ë°‹ ì™„ë£Œ")
            time.sleep(2)

        print(f"\nðŸ“Š ì „ì²´ ìš”ì•½:")
        print(f"  - ê²€ìƒ‰í•œ í‚¤ì›Œë“œ: {len(all_tech_keywords)}ê°œ")
        print(f"  - ë°œê²¬í•œ í‚¤ì›Œë“œ: {len(success_list)}ê°œ")
        print(f"  - í‚¤ì›Œë“œ ëª©ë¡: {success_list[:10]}{'...' if len(success_list) > 10 else ''}")
        print(f"  - ìƒˆë¡œ ì €ìž¥ëœ í‚¤ì›Œë“œ ìˆ˜: {saved_count}")

            
    except Exception as e:
        print(f"âŒ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        raise e
        
    finally:
        if cur:
            cur.close()
            print("ðŸ”„ DB ì»¤ì„œ ì¢…ë£Œ")
        if conn:
            conn.close() 
            print("ðŸ”Œ DB ì—°ê²° ì¢…ë£Œ")

dag = DAG(
    'DICTIONARY_SEARCH_FROM_GITHUB_DAG',
    description='í‚¤ì›Œë“œ ì‚¬ì „êµ¬ì¶•ì„ ìœ„í•œ Github API í˜¸ì¶œ DAG',
    schedule_interval='0 0 * * *', # í•˜ë£¨ì— í•œë²ˆ ì‹¤í–‰
    start_date=datetime(2025, 7, 17),
    catchup=False
)


# Task ì •ì˜
# 1ë‹¨ê³„: ìµœì‹  í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸
update_latest_keywords_task = PythonOperator(
    task_id='update_latest_keywords',
    python_callable=update_latest_keywords,
    dag=dag
)


# ë¼ë²¨ ì„¤ì •
def set_labels():
    return [
        "software development and programming",
        "technology and engineering", 
        "developer tools and infrastructure",
        "political and social issues",
        "entertainment and media",
        "business and finance",
        "personal and lifestyle"
    ]

# ê¸°ìˆ  ë¼ë²¨ ì„¤ì •
def set_tech_labels():
    return [
        "software development and programming",
        "technology and engineering", 
        "developer tools and infrastructure",
    ]

# í—¤ë” ì„¤ì •
def set_headers():
    return {
        'Authorization': f'Bearer {os.environ["GITHUB_TOKEN"]}',
        'Accept': 'application/vnd.github+json'
    }

# DB ì—°ê²°
def set_conn():

    return connect(
        host=os.environ['HOST'],
        database=os.environ['DATABASE'],
        user=os.environ['USER'], 
        password=os.environ['PASSWORD'],
        port=os.environ['PORT']
    )

# DBì—ì„œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
def get_tech_keywords_from_db(cur):
    select_query = """
    SELECT keyword FROM tech_trends.tech_dictionary
    """
    cur.execute(select_query)
    all_tech_keywords = cur.fetchall()

    return all_tech_keywords

# í•˜ë“œì½”ë”© ë°©ì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
def get_tech_keywords_from_predefined():
    return ['framework', 'language']

# í‚¤ì›Œë“œ ì €ìž¥
def save_tech_keywords(cur, new_keyword):
    insert_query = """
    INSERT INTO tech_trends.tech_dictionary (keyword, category) VALUES (%s, 'concept')
    ON CONFLICT (keyword) DO NOTHING
    """
    cur.execute(insert_query, (new_keyword,))
    return cur

# ê¸°ìˆ  í‚¤ì›Œë“œ íŒë³„
# def check_tech_keyword(repo_name, classifier, tech_labels):
#     result = classifier(repo_name, tech_labels)
#     top_label = result['labels'][0]
#     top_score = result['scores'][0]
#     return top_label in tech_labels and top_score > 0.5